Scope of Project: Primary experimentation on evalution of multilinngual-RAG systems. 

Acknowledgment: The RAG pipeline used for experimentation is based on youtube_rag.ipynb. 
    1. Video link: https://youtu.be/BrsocJb-fAo?si=-NrAQ5lF1KYDQoHD 
    2. Github Repository:  https://github.com/svpino/youtube-rag 

Languages: English, Hindi, Bengali

Components of RAG system: (Imagining if it's a chat-bot)
    1. LLM, Embeddings - OpenAI 
    2. Vector Store - Pinecone
    3. LangChain
    4. Chunk size = 100, chunk overlap = 20

Dataset (for each languag has been generated by Chatgpt 3.5 turbo) 
    1. Knowlegde base: 825 words (A story from Mahabharata, an ancient Indian epic)
    2. Evaluation dataset: Size = 20 (Categories = question, response, context, ground_truth)

Evaluation Framework: RAGAS (Metrics = faithfulness, answer_correctness)

Doubt: 
    1. What would be the ideal test conditions?

Possible Scope:
    1. Concluding some results
    2. KB is made such that its pre-exposed to ChatGpt Turbo-3 model
    3. Make an API for translation 
    4. Increasing the number of metrics
    5. Increase size of our dataset {10k-KB(single/multiple stories); 500-Eval}
    6. Connect with SQL database
    7. Making evaluation algorithm in a different file
    8. Making a single multilingual RAG system with cross-lingual capabilities
    9. More to be added...

Results: 
    1. Fluctuation in answers when a question is asked again 
    2. More to be added...